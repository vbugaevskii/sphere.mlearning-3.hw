{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "%%bash\n",
    "wc -l ./data/train.timestamp.txt\n",
    "wc -l ./data/valid.timestamp.txt\n",
    "wc -l ./data/test.timestamp.txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "n_train, n_valid, n_test = 72736664, 7647865, 20095978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62603802, 17780727, 20095978)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = !wc -l ./data/train.timestamp.txt\n",
    "n_valid = !wc -l ./data/valid.timestamp.txt\n",
    "n_test  = !wc -l ./data/test.timestamp.txt\n",
    "\n",
    "n_train, n_valid, n_test = map(lambda x: int(x[0].split()[0]), [n_train, n_valid, n_test])\n",
    "n_train, n_valid, n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users, n_items = 17770, 2649429\n",
    "n_features = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_indexes = tf.sparse_placeholder(tf.float32, name=\"users_indexes\")\n",
    "items_indexes = tf.sparse_placeholder(tf.float32, name=\"items_indexes\")\n",
    "ranks_indexes = tf.placeholder(dtype=tf.int32, shape=[None], name=\"ranks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"users_emebedding\"):\n",
    "    users_weights = tf.Variable(tf.random_normal([n_users, n_features], stddev=0.01), name=\"users_weights\")\n",
    "    users_embedding = tf.sparse_tensor_dense_matmul(users_indexes, users_weights, name=\"users_embedding\")\n",
    "    \n",
    "with tf.name_scope(\"items_embedding\"):\n",
    "    items_weights = tf.Variable(tf.random_normal([n_items, n_features], stddev=0.01), name=\"items_weights\")\n",
    "    items_embedding = tf.sparse_tensor_dense_matmul(items_indexes, items_weights, name=\"items_embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"concatenation\"):\n",
    "    layer_0 = tf.concat([users_embedding, items_embedding], axis=-1, name=\"layer_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_layer(name, prev, dim_out, activation=\"sigmoid\"):\n",
    "    dim_in = int(prev.get_shape()[1])\n",
    "    \n",
    "    with tf.name_scope(name):    \n",
    "        weights = tf.Variable(tf.random_normal([dim_in, dim_out], stddev=0.01), name=\"W\")\n",
    "        bias = tf.Variable(tf.random_normal([dim_out], stddev=0.01), name=\"b\")\n",
    "                \n",
    "        prev = tf.nn.bias_add(tf.matmul(prev, weights, name=\"weights\"), bias, name=\"bias\")\n",
    "        active_func = {\n",
    "            \"sigmoid\":  tf.nn.sigmoid,\n",
    "            \"relu\":     tf.nn.relu,\n",
    "            \"tanh\":     tf.nn.tanh,\n",
    "            \"linear\":   tf.identity\n",
    "        }[activation]\n",
    "        prev = active_func(prev, name=activation)\n",
    "        \n",
    "        return prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_1 = seq_layer(\"layer_1\", layer_0, 10, \"relu\")\n",
    "layer_2 = seq_layer(\"layer_2\", layer_1, 1,  \"relu\")\n",
    "layer_3 = tf.squeeze(layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_loss = tf.losses.mean_squared_error(ranks_indexes, layer_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'loss:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar('loss', t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"/tmp/tensorflow\", tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run:** tensorboard --logdir=run1:/tmp/tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(t_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def get_entry(line):\n",
    "    try:\n",
    "        user, item, time, rank = map(int, line.strip().split(','))\n",
    "        return user, item, time, rank\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "NAME_TRAIN = \"./data/train.timestamp.txt\"\n",
    "NAME_VALID = \"./data/valid.timestamp.txt\"\n",
    "NAME_TEST  = \"./data/test.timestamp.txt\"\n",
    "\n",
    "def batch_iterator(file_name, size=100):\n",
    "    size = int(size)\n",
    "    \n",
    "    cache_size = 10**7\n",
    "    cache = []\n",
    "    \n",
    "    with open(file_name) as f_name:\n",
    "        for line in f_name:\n",
    "            user, item, time, rank = get_entry(line)\n",
    "            cache.append((user-1, item-1, rank))\n",
    "            \n",
    "            if len(cache) == cache_size:\n",
    "                for i in range(0, len(cache), size):\n",
    "                    yield cache[i:i+size]\n",
    "                cache[:] = []\n",
    "        \n",
    "        if len(cache) > 0:\n",
    "            for i in range(0, len(cache), size):\n",
    "                yield cache[i:i+size]\n",
    "        \n",
    "    cache[:] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver.restore(sess, \"./models/model_epoch_{:03}.ckpt\".format(14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~1.00000\n"
     ]
    }
   ],
   "source": [
    "with open(\"./submission_03_05_preformat.csv\", \"w\") as f_submission:\n",
    "    n_processed = 0\n",
    "    \n",
    "    for batch in batch_iterator(NAME_TEST, size=10000):\n",
    "        users_b = map(operator.itemgetter(0), batch)\n",
    "        items_b = map(operator.itemgetter(1), batch)\n",
    "        ranks_b = map(operator.itemgetter(2), batch)\n",
    "        \n",
    "        indices = range(len(batch)) \n",
    "        users_b = np.asarray(zip(indices, users_b))\n",
    "        items_b = np.asarray(zip(indices, items_b))\n",
    "        \n",
    "        values = np.ones(len(batch))\n",
    "        users_shape = (len(batch), n_users)\n",
    "        items_shape = (len(batch), n_items)\n",
    "        \n",
    "        prediction = sess.run(layer_3, feed_dict={\n",
    "            users_indexes: (users_b, values, users_shape),\n",
    "            items_indexes: (items_b, values, items_shape),\n",
    "            ranks_indexes: np.asarray(ranks_b)\n",
    "        })\n",
    "        \n",
    "        n_processed += len(batch)\n",
    "        \n",
    "        if n_processed % 1000 == 0:\n",
    "            print \"\\r~{:>6.5f}\".format(n_processed / 20095978.0),\n",
    "            \n",
    "        for pred in prediction:\n",
    "            f_submission.write(\"{:.5f}\".format(pred))\n",
    "            f_submission.write(\"\\n\")\n",
    "    \n",
    "    print \"\\r~{:>6.5f}\".format(1.0),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
